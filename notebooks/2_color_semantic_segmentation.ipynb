{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorization of Semantic Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pointtree.visualization import color_semantic_segmentation\n",
    "from pointtree.io import PointCloudReader, PointCloudWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point cloud files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '<insert path>'\n",
    "\n",
    "datasets = {\n",
    "    'TreeML': {\n",
    "        '2023-01-09_tum_campus': {\n",
    "            'file_path': '2023-01-09_tum_campus.laz',\n",
    "            'street': '2023-01-09\\_tum\\_campus',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-16_12': {\n",
    "            'file_path': '2023-01-16_12.laz',\n",
    "            'street': '2023-01-16\\_12',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-16_43': {\n",
    "            'file_path': '2023-01-16_43.laz',\n",
    "            'street': '2023-01-16\\_43',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-12_57': {\n",
    "            'file_path': '2023-01-12_57.laz',\n",
    "            'street': '2023-01-12\\_57',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-12_58': {\n",
    "            'file_path': '2023-01-12_58.laz',\n",
    "            'street': '2023-01-12\\_58',\n",
    "            'part': ''\n",
    "        },\n",
    "    },\n",
    "    'Essen': {\n",
    "        'altendorfer_part_1': {\n",
    "            'file_path': 'Altendorfer_p1_min_1.laz',\n",
    "            'street': 'Altendorfer Straße',\n",
    "            'part': 'part 1',\n",
    "        },\n",
    "        'altendorfer_part_2': {\n",
    "            'file_path': 'Altendorfer_p2_min_1.laz',\n",
    "            'street': 'Altendorfer Straße',\n",
    "            'part': 'part 2'\n",
    "        },\n",
    "        'altenessener_part_4': {\n",
    "            'file_path': 'Essen3_p2_min_1.laz',\n",
    "            'street': 'Altenessener Straße',\n",
    "            'part': 'part 4'\n",
    "        },\n",
    "        'altenessener_part_5': {\n",
    "            'file_path': 'Essen3_p3_min_1.laz',\n",
    "            'street': 'Altenessener Straße',\n",
    "            'part': 'part 5'\n",
    "        }\n",
    "    },\n",
    "    'Hamburg': {\n",
    "        'armgart_straße_part_1': {\n",
    "            'file_path': '000274_v2_min_1.laz',\n",
    "            'street': 'Armgartstraße',\n",
    "            'part': 'part 1'\n",
    "\n",
    "        },\n",
    "        'armgart_straße_part_2': {\n",
    "            'file_path': '000275_000276_min_1.laz',\n",
    "            'street': 'Armgartstraße',\n",
    "            'part': 'part 2'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PointCloudReader()\n",
    "writer = PointCloudWriter()\n",
    "\n",
    "for dataset in datasets:\n",
    "    for file_id, file_infos in datasets[dataset].items():\n",
    "        print(\"Process\", file_id)\n",
    "\n",
    "        point_cloud_io_data = pd.read_csv(os.path.join(base_dir, 'Data', dataset, '3_semantic_segmentation_processed', file_infos['file_path']))\n",
    "        point_cloud = point_cloud_io_data.data\n",
    "\n",
    "\n",
    "        classes_to_colors = {\n",
    "            1: \"4F2A17\",  # tree trunk\n",
    "            2: \"1F5C33\",  # tree crown\n",
    "            3: \"8D5C2A\",  # tree branch\n",
    "            4: \"C2D24B\"  # low vegetation\n",
    "        }\n",
    "\n",
    "        point_cloud = color_semantic_segmentation(point_cloud, classes_to_colors=classes_to_colors, semantic_segmentation_column=\"classification_prediction\")\n",
    "\n",
    "        colored_dir = os.path.join(base_dir, 'Data', dataset, '4_semantic_segmentation_colored')\n",
    "        os.makedirs(colored_dir, exist_ok=True)\n",
    "       \n",
    "        point_cloud_io_data.data = point_cloud\n",
    "        writer.write(point_cloud_io_data, os.path.join(colored_dir, file_infos['file_path'].replace(\".csv\", \".laz\")), columns=[\"x\", \"y\", \"z\", \"r\", \"g\", \"b\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
