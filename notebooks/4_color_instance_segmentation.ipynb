{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorization of Instance Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pointtree.visualization import color_instance_segmentation\n",
    "from pointtree.io import PointCloudReader, PointCloudWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point cloud files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '<insert path>'\n",
    "\n",
    "datasets = {\n",
    "    'TreeML': {\n",
    "        '2023-01-09_tum_campus': {\n",
    "            'file_path': '2023-01-09_tum_campus.laz',\n",
    "            'street': '2023-01-09\\_tum\\_campus',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-16_12': {\n",
    "            'file_path': '2023-01-16_12.laz',\n",
    "            'street': '2023-01-16\\_12',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-16_43': {\n",
    "            'file_path': '2023-01-16_43.laz',\n",
    "            'street': '2023-01-16\\_43',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-12_57': {\n",
    "            'file_path': '2023-01-12_57.laz',\n",
    "            'street': '2023-01-12\\_57',\n",
    "            'part': ''\n",
    "        },\n",
    "        '2023-01-12_58': {\n",
    "            'file_path': '2023-01-12_58.laz',\n",
    "            'street': '2023-01-12\\_58',\n",
    "            'part': ''\n",
    "        },\n",
    "    },\n",
    "    'Essen': {\n",
    "        'altendorfer_part_1': {\n",
    "            'file_path': 'Altendorfer_p1_min_1.laz',\n",
    "            'street': 'Altendorfer Straße',\n",
    "            'part': 'part 1',\n",
    "        },\n",
    "        'altendorfer_part_2': {\n",
    "            'file_path': 'Altendorfer_p2_min_1.laz',\n",
    "            'street': 'Altendorfer Straße',\n",
    "            'part': 'part 2'\n",
    "        },\n",
    "        'altenessener_part_4': {\n",
    "            'file_path': 'Essen3_p2_min_1.laz',\n",
    "            'street': 'Altenessener Straße',\n",
    "            'part': 'part 4'\n",
    "        },\n",
    "        'altenessener_part_5': {\n",
    "            'file_path': 'Essen3_p3_min_1.laz',\n",
    "            'street': 'Altenessener Straße',\n",
    "            'part': 'part 5'\n",
    "        }\n",
    "    },\n",
    "    'Hamburg': {\n",
    "        'armgart_straße_part_1': {\n",
    "            'file_path': '000274_v2_min_1.laz',\n",
    "            'street': 'Armgartstraße',\n",
    "            'part': 'part 1'\n",
    "        },\n",
    "        'armgart_straße_part_2': {\n",
    "            'file_path': '000275_000276_min_1.laz',\n",
    "            'street': 'Armgartstraße',\n",
    "            'part': 'part 2'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PointCloudReader()\n",
    "writer = PointCloudWriter()\n",
    "\n",
    "for dataset in datasets:\n",
    "    for file_id, file_infos in datasets[dataset].items():\n",
    "        for algorithm_variant in [\"w_c\", \"w_tc\", \"w_v\", \"w_rg\"]:\n",
    "            for experiment_label in [\"gt\", \"dl\"]:\n",
    "\n",
    "                file_name = f'{\".\".join(file_infos[\"file_path\"].split(\".\")[:-1])}_{algorithm_variant}_{experiment_label}.csv'\n",
    "                file_path = os.path.join(base_dir, 'Data', dataset, '5_instance_segmentation', file_name)\n",
    "                if os.path.exists(file_path):\n",
    "                    print(\"Process\", file_id)\n",
    "                    point_cloud_io_data = pd.read_csv(file_path)\n",
    "                    point_cloud = point_cloud_io_data.data\n",
    "\n",
    "                    point_cloud = color_instance_segmentation(point_cloud, instance_id_column=\"instance_id_predicted\")\n",
    "\n",
    "                    colored_dir = os.path.join(base_dir, 'Data', dataset, '7_instance_segmentation_colored')\n",
    "                    os.makedirs(colored_dir, exist_ok=True)\n",
    "                \n",
    "                    point_cloud_io_data.data = point_cloud\n",
    "                    writer.write(point_cloud_io_data, os.path.join(colored_dir, file_infos['file_path'].replace(\".csv\", \".laz\")), columns=[\"x\", \"y\", \"z\", \"r\", \"g\", \"b\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
